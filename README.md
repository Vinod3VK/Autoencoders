# Autoencoders: Teaching Machines to Reconstruct What Matters

ğŸ“ **Project Type**: MSc Data Science â€“ Individual Machine Learning Assignment  
ğŸ§  **Topic**: Autoencoders â€“ Compression and Denoising  
âœï¸ **Author**: [Your Name]  
ğŸ“ **Student Number**: 230XXXXX  
ğŸ”— **Tutorial PDF**: [Link to uploaded file or repo PDF]

---

## ğŸ” Overview

This project explores the concept of **Autoencoders**, a type of neural network used for unsupervised learning. The focus is on building a basic autoencoder to compress and reconstruct MNIST digit images, followed by a **denoising autoencoder** to remove Gaussian noise from the images.

---

## ğŸ’» Files Included

- `autoencoder_mnist_tutorial.ipynb` â€“ Full code with training, visualization, and denoising implementation
- `autoencoder_tutorial_expanded.pdf` â€“ The written tutorial (under 2000 words)
- `autoencoder_architecture.png` â€“ A diagram showing the model architecture

---

## ğŸ§  Key Topics Covered

- Encoder/Decoder structure
- Latent space representation
- Denoising autoencoders
- Reconstruction visualization
- Use of MNIST dataset

---

## ğŸ“Š Getting Started

To run the notebook:
```bash
pip install tensorflow matplotlib numpy
```
Then open in Jupyter or Colab and run all cells.

---

## âš–ï¸ License

This project is licensed under the MIT License. See `LICENSE` file for details.

---

## ğŸ“š References

See the "References" section at the bottom of the tutorial PDF. All key sources are listed, including Deep Learning textbooks and Keras documentation.
